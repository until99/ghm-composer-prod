# GHM Composer Production - Data Pipelines

Pipeline de dados orquestrado pelo Google Cloud Composer (Apache Airflow) seguindo arquitetura Medallion (Bronze ‚Üí Silver ‚Üí Gold) com **gera√ß√£o autom√°tica de DAGs via YAML**.

---

## üèóÔ∏è Arquitetura

```
Oracle TASY ‚Üí [Bronze Layer] ‚Üí [Silver Layer] ‚Üí [Gold Layer] ‚Üí BigQuery Analytics
              (schedule)      (triggered)      (triggered)
```

**Fluxo**:

1. **Bronze** roda agendado (`@daily`, `@monthly`)
2. Ao completar, atualiza **Dataset** do Airflow
3. **Silver** √© automaticamente triggered
4. Silver limpa/transforma dados
5. **Gold** √© triggered quando Silver completa
6. Gold calcula m√©tricas agregadas

> **Dataset Triggers**: DAGs downstream s√≥ executam quando upstream completa com sucesso.

---

## üìÇ Estrutura do Projeto

```
ghm-composer-prod/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ pipelines.yaml           # ‚Üê Configura√ß√£o de TODAS as pipelines
‚îÇ
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ dag_generator.py         # ‚Üê Gera DAGs automaticamente do YAML
‚îÇ   ‚îî‚îÄ‚îÄ teste_conexao.py         # DAG de teste
‚îÇ
‚îú‚îÄ‚îÄ sql/
‚îÇ   ‚îú‚îÄ‚îÄ bronze_*.sql             # Queries de extra√ß√£o Oracle
‚îÇ   ‚îú‚îÄ‚îÄ silver_*.sql             # Queries de transforma√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ gold_*.sql               # Queries de agrega√ß√£o
‚îÇ
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ yaml_loader.py           # Carregador YAML
    ‚îú‚îÄ‚îÄ dag_factory.py           # Factory de DAGs
    ‚îú‚îÄ‚îÄ task_templates.py        # Templates reutiliz√°veis
    ‚îî‚îÄ‚îÄ sql_helpers.py           # Helpers SQL
```

---

## üöÄ Quick Start - Adicionar Nova Pipeline

### 1Ô∏è‚É£ Edite o YAML

```yaml
# config/pipelines.yaml
bronze:
  nova_tabela:
    dataset: bronze_domain
    table: nova_tabela
    schedule: "@daily"
    sql_file: bronze_nova_tabela.sql
    gcs_path: stage/nova_tabela/{{ ds }}/dados.parquet
    write_disposition: WRITE_APPEND
    tags: [bronze, oracle, tasy]
```

### 2Ô∏è‚É£ Crie o SQL

```sql
-- sql/bronze_nova_tabela.sql
SELECT
    CD_CAMPO,
    NM_CAMPO,
    DT_ATUALIZACAO
FROM DBAMV.NOVA_TABELA
WHERE DT_ATUALIZACAO >= TRUNC(SYSDATE - 1)
```

### 3Ô∏è‚É£ Deploy

```bash
git add config/pipelines.yaml sql/bronze_nova_tabela.sql
git commit -m "feat: adiciona pipeline bronze_nova_tabela"
git push
```

O CI/CD automaticamente faz sync de:

- `dags/` ‚Üí `gs://BUCKET/dags/`
- `utils/` ‚Üí `gs://BUCKET/dags/utils/`
- `config/` ‚Üí `gs://BUCKET/config/`
- `sql/` ‚Üí `gs://BUCKET/sql/`

**Pronto!** A DAG `bronze_nova_tabela` ser√° criada automaticamente. ‚ú®

---

## üìù Configura√ß√£o YAML

### Estrutura B√°sica

```yaml
global:
  project_id: ghm-data-prod
  oracle_conn_id: tasy_prod_oracle_conn
  bucket_name: ghm-data-prod-composer-bucket-001
  default_retries: 0
  default_retry_delay: 300

bronze:
  tb_raw:
    dataset: bronze_tb_raw
    table: tb_raw
    schedule: "@daily"
    sql_file: bronze_tb_raw.sql
    gcs_path: stage/tb_raw/{{ ds }}/dados.parquet
    write_disposition: WRITE_APPEND | WRITE_TRUNCATE | WRITE_EMPTY
    tags: [bronze, oracle, tasy, raw]

silver:
  td_raw:
    dataset: silver_td_raw
    table: td_raw
    sql_file: silver_td_raw.sql
    write_disposition: WRITE_TRUNCATE
    tags: [silver, dimension, raw]
    dependencies:
      - bronze_td_raw # Aguarda Bronze completar

gold:
  tf_raw:
    dataset: gold_raw
    table: tf_raw
    sql_file: gold_tf_raw.sql
    write_disposition: WRITE_TRUNCATE
    tags: [gold, analytics, metrics]
    dependencies:
      - silver_td_raw # Aguarda Silver completar
```

### Campos Dispon√≠veis

#### Global (obrigat√≥rio)

- `project_id`: ID do projeto GCP
- `oracle_conn_id`: Connection ID do Airflow
- `bucket_name`: Bucket GCS para staging
- `default_owner`: Owner das DAGs
- `default_retries`: Tentativas padr√£o
- `default_retry_delay`: Delay entre retries (segundos)

#### Bronze

- `dataset`: Dataset BigQuery
- `table`: Nome da tabela
- `schedule`: `@daily`, `@hourly`, `@monthly`, ou cron
- `sql_file`: Nome do arquivo SQL (em `sql/`)
- `gcs_path`: Caminho GCS (usa `{{ ds }}` para data)
- `write_disposition`: `WRITE_APPEND` ou `WRITE_TRUNCATE`
- `tags`: Lista de tags
- `use_temp_table` (opcional): `true` para usar tabela tempor√°ria
- `temp_table_suffix` (opcional): Sufixo da temp table (padr√£o: `_temp`)

#### Silver / Gold

- `dataset`: Dataset BigQuery
- `table`: Nome da tabela
- `sql_file`: Nome do arquivo SQL
- `write_disposition`: `WRITE_TRUNCATE` (geralmente)
- `tags`: Lista de tags
- `dependencies`: Lista de DAGs que devem completar antes

---

## üìä Pipelines Configuradas

Atualmente em `config/pipelines.yaml`:

### Bronze (Ingest√£o Oracle)

- `bronze_td_paciente` - Dimens√£o pacientes (@daily)
- `bronze_tb_atendimento_paciente` - Atendimentos (@monthly, usa temp table)

### Silver (Transforma√ß√£o)

- `silver_paciente_consolidated` - Consolida√ß√£o de dados
  - Triggered por: `bronze_td_paciente`, `bronze_tb_atendimento_paciente`

### Gold (M√©tricas)

- `gold_paciente_metrics` - KPIs agregados
  - Triggered por: `silver_paciente_consolidated`

---

## üõ†Ô∏è Desenvolvimento Local

### Setup

```bash
# Instalar depend√™ncias
uv sync

# Ativar ambiente
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

### Testar

```bash
# Validar DAG
python -c "from utils import get_all_pipelines; print(get_all_pipelines())"

# Testar gera√ß√£o
python dags/dag_generator.py

# Validar SQL no BigQuery Console
# (copie conte√∫do de sql/*.sql)
```

---

## üîç Monitoramento

### Airflow UI

- **DAGs**: `/home` - Lista todas as DAGs geradas
- **Datasets**: `/datasets` - Visualiza depend√™ncias entre camadas
- **Graph**: Clique na DAG ‚Üí Graph - Fluxo de tasks

### BigQuery

- Monitore custos e performance
- Valide particionamento/clustering
- Verifique qualidade dos dados

---

## üìã Padr√µes de DAG Gerados

### Bronze (Padr√£o)

```
extract_oracle_to_gcs ‚Üí load_gcs_to_bq
```

### Bronze (Com Temp Table)

```
extract_oracle_to_gcs ‚Üí load_to_temp_table ‚Üí move_to_final_table
```

### Silver / Gold

```
transform_to_[layer]
```

Todas as configura√ß√µes do YAML (retries, timeouts, dependencies, tags) s√£o aplicadas automaticamente.

---

## üéØ Conven√ß√µes

### Nomenclatura

- **DAG ID**: `{layer}_{nome_tabela}`
- **SQL files**: `{layer}_{nome_tabela}.sql`
- **Tasks**: Verbos (`extract_`, `load_`, `transform_`)

### Tags por Layer

- **Bronze**: `[bronze, oracle, tasy, tb, dominio]`
- **Silver**: `[silver, td, dominio]`
- **Gold**: `[gold, tf, metrics]`

### Write Disposition

- **Bronze**: `WRITE_APPEND` (mant√©m hist√≥rico)
- **Silver/Gold**: `WRITE_TRUNCATE` (full refresh)

---

## üö® Troubleshooting

### DAG n√£o aparece no Airflow

```python
# Verifique se o YAML √© v√°lido
from utils import get_pipeline_config
config = get_pipeline_config("bronze_sua_tabela")
print(config)
```

### Erro "Pipeline not found"

- Verifique nome no YAML (ex: `td_paciente`, n√£o `bronze_td_paciente`)
- DAG ID √© gerado como `{layer}_{nome}` automaticamente

### Recarregar configura√ß√£o

```python
from utils import reload_config
reload_config()
```

### Erro de depend√™ncia

- Certifique-se que DAGs upstream existem no YAML
- Use o DAG ID correto em `dependencies`

---

## ü§ù Contribuindo

1. Edite `config/pipelines.yaml`
2. Crie arquivo SQL correspondente
3. Teste localmente (`uv sync`, valida√ß√£o)
4. Commit com mensagem descritiva

---

## üìû Contato

- **Owner**: Gabriel Kasten
- **Projeto GCP**: ghm-data-prod
- **Reposit√≥rio**: until99/ghm-composer-prod

---

**√öltima atualiza√ß√£o**: Dezembro 2025
